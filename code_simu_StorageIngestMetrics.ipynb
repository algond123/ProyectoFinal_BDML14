{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos con spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, round as spark_round, mean\n",
    "from pyspark.sql.functions import stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear Spark session y cargar la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear sesi贸n de Spark (agrega el path real del driver JDBC si es necesario)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SpotifyFromDB_Metrics\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.security.manager\", \"false\") \\\n",
    "    .config(\"spark.hadoop.security.manager\", \"None\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"./Code/libs/sqlite-jdbc.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Leer desde SQLite\n",
    "jdbc_url = \"jdbc:sqlite:./Code/Data/spotify_data.db\"\n",
    "\n",
    "df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"dbtable\", \"tracks\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confirmar estructura\n",
    "df.printSchema()\n",
    "df.select(\"track_name\", \"energy\", \"tempo\", \"loudness\", \"danceability\", \"valence\").show(10)\n",
    "\n",
    "# Filtrar columnas necesarias y eliminar nulos\n",
    "features = ['energy', 'tempo', 'loudness', 'danceability', 'valence']\n",
    "df = df.select(*features).na.drop()\n",
    "\n",
    "# Clipping\n",
    "df = df.withColumn(\"tempo\", when(col(\"tempo\") < 20, 20).when(col(\"tempo\") > 200, 200).otherwise(col(\"tempo\")))\n",
    "df = df.withColumn(\"loudness\", when(col(\"loudness\") < -60, -60).when(col(\"loudness\") > 0, 0).otherwise(col(\"loudness\")))\n",
    "df = df.withColumn(\"energy\", when(col(\"energy\") < 0, 0).when(col(\"energy\") > 1, 1).otherwise(col(\"energy\")))\n",
    "df = df.withColumn(\"danceability\", when(col(\"danceability\") < 0, 0).when(col(\"danceability\") > 1, 1).otherwise(col(\"danceability\")))\n",
    "\n",
    "# Escalado Min-Max\n",
    "df = df.withColumn(\"tempo\", (col(\"tempo\") - 20) / (200 - 20))\n",
    "df = df.withColumn(\"loudness\", (col(\"loudness\") + 60) / 60)\n",
    "\n",
    "# C谩lculo de 'arousal'\n",
    "alpha, beta, gamma, delta = 0.5, 0.25, 0.2, 0.05\n",
    "\n",
    "df = df.withColumn(\"arousal\",\n",
    "    spark_round(\n",
    "        alpha * col(\"energy\") +\n",
    "        beta * col(\"tempo\") +\n",
    "        gamma * col(\"loudness\") +\n",
    "        delta * col(\"danceability\"),\n",
    "        3\n",
    "    )\n",
    ")\n",
    "\n",
    "# Redondear columnas\n",
    "for feature in ['energy', 'tempo', 'loudness', 'danceability', 'arousal', 'valence']:\n",
    "    df = df.withColumn(feature, spark_round(col(feature), 3))\n",
    "\n",
    "# Nueva estructura\n",
    "df.printSchema()\n",
    "df.select(\"arousal\", \"valence\", \"energy\", \"tempo\", \"loudness\", \"danceability\", \"valence\").show(10)\n",
    "\n",
    "# 1. **Metrics for All Columns**\n",
    "print(\"\\n Metrics for All Columns:\")\n",
    "df.describe().show()\n",
    "\n",
    "# 2. **Metrics for Selected Features**\n",
    "print(\"\\n Metrics for Selected Features:\")\n",
    "df.select(\"energy\", \"tempo\", \"loudness\", \"danceability\", \"arousal\", \"valence\").describe().show()\n",
    "\n",
    "# 3. **Correlation between energy and arousal**\n",
    "correlation_matrix = df.select(\"energy\", \"arousal\").stat.corr(\"energy\", \"arousal\")\n",
    "print(f\"Correlation between energy and arousal: {correlation_matrix}\\n\")\n",
    "\n",
    "# 4. **Skewness of each feature**\n",
    "skewness = df.select(\"energy\", \"tempo\", \"loudness\", \"danceability\", \"arousal\", \"valence\").agg(\n",
    "    {\"energy\": \"skewness\", \"tempo\": \"skewness\", \"loudness\": \"skewness\", \"danceability\": \"skewness\", \"arousal\": \"skewness\", \"valence\": \"skewness\"}\n",
    ")\n",
    "print(\"\\nSkewness of each feature:\")\n",
    "skewness.show()\n",
    "\n",
    "# 5. **Quantiles of each feature**\n",
    "quantiles = df.select(\"energy\", \"tempo\", \"loudness\", \"danceability\", \"arousal\", \"valence\").approxQuantile(\n",
    "    \"energy\", [0.25, 0.5, 0.75], 0.05\n",
    ")\n",
    "print(f\"Energy quantiles: {quantiles}\\n\")\n",
    "\n",
    "# 6. **Standard Deviation of each feature**\n",
    "stddev = df.select(\"energy\", \"tempo\", \"loudness\", \"danceability\", \"arousal\", \"valence\").agg(\n",
    "    stddev(\"energy\").alias(\"stddev_energy\"),\n",
    "    stddev(\"tempo\").alias(\"stddev_tempo\"),\n",
    "    stddev(\"loudness\").alias(\"stddev_loudness\"),\n",
    "    stddev(\"danceability\").alias(\"stddev_danceability\"),\n",
    "    stddev(\"arousal\").alias(\"stddev_arousal\"),\n",
    "    stddev(\"valence\").alias(\"stddev_valence\")\n",
    ")\n",
    "print(\"\\nStandard Deviation of each feature:\")\n",
    "stddev.show()\n",
    "\n",
    "# 7. **Kurtosis of each feature**\n",
    "kurtosis = df.select(\"energy\", \"tempo\", \"loudness\", \"danceability\", \"arousal\", \"valence\").agg(\n",
    "    {\"energy\": \"kurtosis\", \"tempo\": \"kurtosis\", \"loudness\": \"kurtosis\", \"danceability\": \"kurtosis\", \"arousal\": \"kurtosis\", \"valence\": \"kurtosis\"}\n",
    ")\n",
    "print(\"\\nKurtosis of each feature:\")\n",
    "kurtosis.show()\n",
    "\n",
    "# 8. **Variance of each feature**\n",
    "variance = df.select(\"energy\", \"tempo\", \"loudness\", \"danceability\", \"arousal\", \"valence\").agg(\n",
    "    {\"energy\": \"variance\", \"tempo\": \"variance\", \"loudness\": \"variance\", \"danceability\": \"variance\", \"arousal\": \"variance\", \"valence\": \"variance\"}\n",
    ")\n",
    "print(\"\\nVariance of each feature:\")\n",
    "variance.show()\n",
    "\n",
    "# 9. **Min and Max values of each feature**\n",
    "min_max_values = df.select(\"energy\", \"tempo\", \"loudness\", \"danceability\", \"arousal\", \"valence\").agg(\n",
    "    {\"energy\": \"min\", \"energy\": \"max\", \"tempo\": \"min\", \"tempo\": \"max\", \"loudness\": \"min\", \"loudness\": \"max\", \n",
    "     \"danceability\": \"min\", \"danceability\": \"max\", \"arousal\": \"min\", \"arousal\": \"max\", \"valence\": \"min\", \"valence\": \"max\"}\n",
    ")\n",
    "print(\"\\nMin and Max values of each feature:\")\n",
    "min_max_values.show()\n",
    "\n",
    "# 10. **Final Statistics for arousal and valence**\n",
    "print(\"\\n Final Statistics for Arousal and Valence:\")\n",
    "df.select(\"arousal\", \"valence\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerrar sesion y gaurdar en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar (opcional)\n",
    "df.select(\"arousal\", \"valence\") \\\n",
    "    .write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(\"./Code/Data/spark_arousal_valence_output.csv\")\n",
    "\n",
    "# Detener Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulacion de envio (REST) de datos en timepo real (Ingesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "df = pd.read_csv('./Code/Source/cancionesSpotify.csv') # executed from powershell \n",
    "\n",
    "for index, row in df.head(20).iterrows():\n",
    "    json_data = row.to_dict()\n",
    "    \n",
    "    print(f\"Enviando registro {index + 1}...\")\n",
    "    response = requests.post(\"http://localhost:8888/ingest\", json=json_data)\n",
    "\n",
    "    try:\n",
    "        print(response.json())\n",
    "    except:\n",
    "        print(\"Error al interpretar la respuesta del servidor.\")\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulacion de recepcion (REST) de datos y creacion de la base de datos con SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import sqlite3\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "DB_PATH = './Code/Data/spotify_data.db'\n",
    "\n",
    "def init_db():\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        conn.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS tracks (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                track_id TEXT UNIQUE,\n",
    "                artists TEXT,\n",
    "                album_name TEXT,\n",
    "                track_name TEXT,\n",
    "                popularity INTEGER,\n",
    "                duration_ms INTEGER,\n",
    "                explicit BOOLEAN,\n",
    "                danceability REAL,\n",
    "                energy REAL,\n",
    "                key INTEGER,\n",
    "                loudness REAL,\n",
    "                mode INTEGER,\n",
    "                speechiness REAL,\n",
    "                acousticness REAL,\n",
    "                instrumentalness REAL,\n",
    "                liveness REAL,\n",
    "                valence REAL,\n",
    "                tempo REAL,\n",
    "                time_signature INTEGER,\n",
    "                track_genre TEXT\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "\n",
    "@app.route('/ingest', methods=['POST'])\n",
    "def ingest_data():\n",
    "    data = request.get_json()\n",
    "    if not data:\n",
    "        return jsonify({\"status\": \"error\", \"message\": \"No se recibieron datos\"}), 400\n",
    "\n",
    "    with sqlite3.connect('./Code/Data/spotify_data.db') as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT 1 FROM tracks WHERE track_id = ?\", (data['track_id'],))\n",
    "        exists = cursor.fetchone()\n",
    "\n",
    "        if exists:\n",
    "            return jsonify({\"status\": \"info\", \"message\": \"Canci贸n ya existe, no se insert贸\"}), 200\n",
    "\n",
    "        try:\n",
    "            cursor.execute('''\n",
    "                INSERT INTO tracks (\n",
    "                    track_id, artists, album_name, track_name, popularity,\n",
    "                    duration_ms, explicit, danceability, energy, key,\n",
    "                    loudness, mode, speechiness, acousticness, instrumentalness,\n",
    "                    liveness, valence, tempo, time_signature, track_genre\n",
    "                ) VALUES (\n",
    "                    :track_id, :artists, :album_name, :track_name, :popularity,\n",
    "                    :duration_ms, :explicit, :danceability, :energy, :key,\n",
    "                    :loudness, :mode, :speechiness, :acousticness, :instrumentalness,\n",
    "                    :liveness, :valence, :tempo, :time_signature, :track_genre\n",
    "                )\n",
    "            ''', data)\n",
    "            conn.commit()\n",
    "        except Exception as e:\n",
    "            logging.error(\"Error al insertar en la base de datos: %s\", e)\n",
    "            return jsonify({\"status\": \"error\", \"message\": str(e)}), 500\n",
    "\n",
    "    return jsonify({\"status\": \"success\", \"message\": \"Canci贸n insertada correctamente\"}), 200\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    init_db()\n",
    "    app.run(debug=True, port=8888)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
